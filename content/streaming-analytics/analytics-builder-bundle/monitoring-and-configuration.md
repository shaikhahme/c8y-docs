---
weight: 100
title: Monitoring and configuration
layout: redirect
---

### Monitoring {#monitoring}
You can monitor the current status of each model in the model manager. The card for a model shows the current mode for this model \(such as production mode\) and whether it is active \(deployed\) or inactive.

![Card for a model](/images/streaming-analytics/analytics-builder/card-with-runtime-error.png)

If a model failed to deploy or failed while running, a runtime error icon <img src="/images/streaming-analytics/analytics-builder/runtime_error.png" alt="Runtime error" style="display:inline-block; margin:0"> is shown on the card for the model.

To find out whether a model has failed while processing data, reload all models in the model manager to show their latest states.
See also [Reloading all models](/streaming-analytics/analytics-builder/#reloading-all-models).

#### Monitoring periodic status {#monitoring-periodic-status}

In addition to the status that is shown on the card for a model, it is possible to enable generation of periodic status published as {{< product-c8y-iot >}} operations or events. See [Configuration](/streaming-analytics/analytics-builder/#configuration) on setting the `status_device_name` and `status_period_secs` tenant options.

Each operation has the following parameters:

<table>
<colgroup>
    <col style="width: 30%;">
    <col style="width: 70%;">
</colgroup>
<thead>
  <tr>
    <th>Parameter</th>
    <th>Description</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td><code>models_running</code></td>
    <td>Information about deployed models that are running.</td>
  </tr>
  <tr>
    <td><code>models_failed</code></td>
    <td>Information about deployed models that have failed.</td>
  </tr>
  <tr>
    <td><code>chain_diagnostics</code></td>
    <td>Information about model chains. See <a href="/streaming-analytics/analytics-builder/#connections-between-models">Connections between models</a> for more information.</td>
  </tr>
  <tr>
    <td><code>apama_status</code></td>
    <td>The Apama correlator status metrics. Many status names correspond to the key names in the Apama REST API. The values are returned by the <code>getValues()</code> action of the <code>com.apama.correlator.EngineStatus</code> event and exposed via the REST API.</td>
  </tr>
</tbody>
</table>

##### Model status {#model-status}

The following information is published for each deployed model that is currently running or has failed:

<table>
<colgroup>
    <col style="width: 30%;">
    <col style="width: 70%;">
</colgroup>
<thead>
  <tr>
    <th>Name</th>
    <th>Description</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td><code>mode</code></td>
    <td>The mode of the deployed model. It is <code>SIMULATION</code> for models deployed in simulation mode. Otherwise, it is <code>PRODUCTION</code>.</td>
  </tr>
  <tr>
    <td><code>modeProperties</code></td>
    <td>Any mode-specific properties of the model. This includes the start and end time of the simulation for models running in the <code>SIMULATION</code> mode.</td>
  </tr>
  <tr>
    <td><code>numModelEvaluations</code></td>
    <td>The total number of times the model has been evaluated since it was deployed.</td>
  </tr>
  <tr>
    <td><code>numBlockEvaluations</code></td>
    <td>The total number of times that the blocks have been evaluated in the model since it was deployed. This is the sum of the count of evaluation for each block in the model.</td>
  </tr>
  <tr>
    <td><code>avgBlockEvaluations</code></td>
    <td>The average number of blocks that have been evaluated per model evaluation.</td>
  </tr>
  <tr>
    <td><code>numOutputGenerated</code></td>
    <td>The total number of outputs generated by the model since it was deployed.</td>
  </tr>
</tbody>
</table>

This information about each model provides insight into the performance or working of models. For example, a model with a much larger number of `numBlockEvaluations` than another model might indicate that it is consuming most resources even though it might have low `numModelEvaluations`. Similarly, it can be used to find out whether a model is producing output at the expected rate relative to the number of times it is evaluated.

You can monitor the status using the Apama REST API or the Management interface which is an EPL plug-in. See the following topics in the Apama product documentation for further information:

- [Managing and Monitoring over REST]({{< link-apama-webhelp >}}index.html#page/pam-webhelp%2Fco-DepAndManApaApp_managing_and_monitoring_over_rest.html)
- [Using the Management interface]({{< link-apama-webhelp >}}index.html#page/pam-webhelp%2Fco-DevApaAppInEpl_using_the_management_interface.html)

##### Chain diagnostics {#chain-diagnostics}

The following information is published for all chains that are present:

<table>
<colgroup>
    <col style="width: 30%;">
    <col style="width: 70%;">
</colgroup>
<thead>
  <tr>
    <th>Name</th>
    <th>Description</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td><code>creationTime</code></td>
    <td>The time when this chain was created.</td>
  </tr>
  <tr>
    <td><code>executionCount</code></td>
    <td>The number of times the chain was evaluated. (1)</td>
  </tr>
  <tr>
    <td><code>modelsInEvalOrder</code></td>
    <td>A list of model identifiers in the order in which the models were evaluated.</td>
  </tr>
  <tr>
    <td><code>pendingTimersCount</code></td>
    <td>The number of pending timers which are behind the current time.</td>
  </tr>
  <tr>
    <td><code>maxTime</code></td>
    <td>The maximum time taken to evaluate the chain. (1)</td>
  </tr>
  <tr>
    <td><code>minTime</code></td>
    <td>The minimum time taken to evaluate the chain. (1)</td>
  </tr>
  <tr>
    <td><code>meanTime</code></td>
    <td>The mean time taken to evaluate the chain. (1)</td>
  </tr>
  <tr>
    <td><code>execBucket</code></td>
    <td>The execution time statistics of the chain. (1), (2)</td>
  </tr>
</tbody>
</table>

(1) The fields are updated if the chain is evaluated fully or partially. Partial evaluation of a chain means that only some models of the chain are evaluated.

(2) There are 21 buckets which store the number of times when the execution time falls within the bucket range. Each bucket has size of `timedelay_secs` divided by 10 seconds, except for the last bucket which stretches to infinity. For example, if `timedelay_secs` is 2 seconds, then the first bucket holds the number of times when the chain execution took up to 0.2 seconds, the second bucket holds the number of times when the chain execution took more than 0.2 seconds but up to 0.4 seconds, and so on. See also the following example:

|Bucket|Execution time range|
|------|--------------------|
|1|0 - 0.2|
|2|0.2 - 0.4|
|3|0.4 - 0.6|
|...|...|
|20|3.8 - 4.0|
|21|4.0 - infinity|

For more information on `timedelay_secs`, see [Keys for model timeouts](/streaming-analytics/analytics-builder/#keys-for-model-timeouts).

##### Slowest chain status {#slowest-chain-status}

When chains of models with a high throughput are deployed across multiple workers, it may happen that the chain falls behind in processing input events, creating a backlog of input events that are still to be processed. These chains are referred to as “slow chains”. A message is written to the correlator log if the slowest chain is delayed by more than 1 second. For example:
"Analytics Builder chain of models "Model 1", "Model 2", "Model 3" is slow by 3 seconds."
See [Log files of the Apama-ctrl microservice](/streaming-analytics/troubleshooting/#logfiles) for information on where to find the log.

The following information on the slowest chain is also available in the periodic status that is published as {{< product-c8y-iot >}} operations or events, within the `apama_status` parameter:

<table>
<colgroup>
    <col style="width: 50%;">
    <col style="width: 50%;">
</colgroup>
<thead>
  <tr>
    <th>Name</th>
    <th>Description</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td><code>user-analyticsbuilder.slowestChain.models</code></td>
    <td>All models contained in the slowest chain.</td>
  </tr>
  <tr>
    <td><code>user-analyticsbuilder.slowestChain.delaySec</code></td>
    <td>The number of seconds the chain lags behind in processing the input events.</td>
  </tr>
</tbody>
</table>

##### Example {#example}

The following is an example of the status operation data that is published by {{< product-c8y-iot >}}:

```
{
    "creationTime": "2021-01-05T21:48:54.620+02:00",
    "deviceId": "6518",
    "deviceName": "apama_status",
    "id": "8579",
    "self": "https://myown.iot.com/devicecontrol/operations/8579",
    "status": "PENDING",
    "models_running": {
        "Package Tracking": {
            "mode": "SIMULATION",
            "modeProperties":{"startTime":1533160604, "endTime":1533160614},
            "numModelEvaluations": 68,
            "numBlockEvaluations": 967,
            "avgBlockEvaluations": 14.2,
            "numOutputGenerated": 50
        }
    },
    "models_failed": {
        "Build Pipeline ": {
            "mode": "PRODUCTION",
            "numModelEvaluations": 214,
            "numBlockEvaluations": 671,
            "avgBlockEvaluations": 3.13,
            "numOutputGenerated": 4
        }
    },
    "chain_diagnostics": {
        "780858_780858": {
            "creationTime": 1600252455.164188,
            "executionCount": 4,
            "modelsInEvalOrder": ["780858_780858", "780860_780860"],
            "pendingTimersCount": 1,
            "timeData": {
                "execBucket": [2,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
                "maxTime": 0.00014781951904296875,
                "meanTime": 0.0001152356465657552,
                "minTime": 6.29425048828125e-05
            }
        }
    },
    "apama_status": {
        "user-analyticsbuilder.slowestChain.models": "\"Model 1\", \"Model 2\", \"Model 3\"",
        "user-analyticsbuilder.slowestChain.delaySec": "3",
        "user-analytics-oldEventsDropped": "1",
        "numJavaApplications": "1",
        "numMonitors": "27",
        "user-httpServer.eventsTowardsHost": "1646",
        "numFastTracked": "183",
        "user-httpServer.authenticationFailures": "4",
        "numContexts": "5",
        "slowestReceiverQueueSize": "0",
        "numQueuedFastTrack": "0",
        "mostBackedUpInputContext": "<none>",
        "user-httpServer.failedRequests": "4",
        "slowestReceiver": "<none>",
        "numInputQueuedInput": "0",
        "user-httpServer.staticFileRequests": "0",
        "numReceived": "1690",
        "user-httpServer.failedRequests.marginal": "1",
        "numEmits": "1687",
        "numOutEventsUnAcked": "1",
        "user-httpServer.authenticationFailures.marginal": "1",
        "user-httpServer.status": "ONLINE",
        "numProcesses": "48",
        "numEventTypes": "228",
        "virtualMemorySize": "3177968",
        "numQueuedInput": "0",
        "numConsumers": "3",
        "numOutEventsQueued": "1",
        "uptime": "1383561",
        "numListeners": "207",
        "numOutEventsSent": "1686",
        "mostBackedUpICQueueSize": "0",
        "numSnapshots": "0",
        "mostBackedUpICLatency": "0",
        "numProcessed": "1940",
        "numSubListeners": "207"
    }
}
```

#### Monitoring dropped events {#monitoring-dropped-events}

When a model receives an event, it may be dropped if the correlator delivers or processes it too late. See [Input blocks and event timing](/streaming-analytics/analytics-builder/#input-blocks-and-event-timing).

The total number of dropped events across all models is periodically published as part of the status operation. The count of the number of dropped events is available as a user-defined status value with the name `user-analytics-oldEventsDropped` in the `apama_status` parameter of the status operation. See also [Monitoring periodic status](/streaming-analytics/analytics-builder/#monitoring-periodic-status) for details about the operation.

All dropped input events are also sent to channel `AnalyticsDroppedEvents`, allowing you to implement your own monitoring of the dropped events. A dropped input event sent to the channel `AnalyticsDroppedEvents` is packaged inside an event of type `apama.analyticsbuilder.DroppedEvent`. This allows you to extract the original dropped event and perform any analysis on it, for example, categorizing the number of dropped events per device. This can be achieved by writing EPL that listens for the `DroppedEvent` events, aggregates by device identifier and/or time, and sends measurements to {{< product-c8y-iot >}} that can be monitored. See also [Deploying apps](/streaming-analytics/epl-apps/#deploying-apps).

#### Monitoring the model life-cycle {#monitoring-the-model-life-cycle}

Life-cycle messages are written to the correlator log whenever a model is created or deleted, or when it fails. The log messages may look as follows:

```
Model "Build Pipeline" with PRODUCTION mode has started.
   
Model "Build Pipeline" with PRODUCTION mode has ended.
   
Model "Build Pipeline" with PRODUCTION mode has failed with an error:
IllegalArgumentException - Error while validating parameters for the
block "toggle" of type "apama.analyticskit.blocks.core.Toggle":
The "Set Delay" must be finite and positive: -1.
```

Deploying a model can combine existing models or chains to form a new chain. The formation of a chain may take a while to complete as it may combine multiple existing models and chains. Activation messages are written to the correlator log whenever the activation of a chain is started and completed. For example:

```
Analytics Builder chain of models "Model 1", "Model 2", "Model 3" is being activated.
Analytics Builder chain of models "Model 1", "Model 2", "Model 3" has been activated.
```

See [Log files of the Apama-ctrl microservice](/streaming-analytics/troubleshooting/#logfiles) for information on where to find the log.

### Configuration {#configuration}

You can customize the settings of Analytics Builder, the so-called “tenant options”, by sending REST requests to {{< product-c8y-iot >}}. The key names that you can use with the REST requests are listed in the topics below. A category name is needed along with the key name; this is always `analytics.builder`.

You can find some concrete examples in [Using curl commands for setting various tenant options](/streaming-analytics/analytics-builder/#using-curl-commands-for-setting-various-tenant-options). However, you can use any tool you like.

To change the tenant options, you need ADMIN permission for "Option management". See [Managing permissions](/standard-tenant/managing-permissions/) for more information.

{{< c8y-admon-caution>}}
After you have changed a tenant option using a REST request, the correlator will automatically restart. An alarm with a MAJOR severity will be created in this case; you can view it on the **Alarms** page of the Cockpit application \(see [Working with alarms](/device-management-application/monitoring-and-controlling-devices/#working-with-alarms) for more information\).
{{< /c8y-admon-caution>}}

#### Keys for status reporting {#keys-for-status-reporting}

<table>
<colgroup>
    <col style="width: 30%;">
    <col style="width: 70%;">
</colgroup>
<thead>
  <tr>
    <th>Key name</th>
    <th>Description</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td><code>status_device_name</code></td>
    <td>The name of the {{< product-c8y-iot >}} device to which the status operations are to be published. The default name is <code>apama_status</code>.</td>
  </tr>
  <tr>
    <td><code>status_period_secs</code></td>
    <td>The frequency in seconds at which the status is to be published. The default value is 0 seconds, meaning that status reporting is disabled. You can enable status reporting by setting the frequency to a positive value.</td>
  </tr>
  <tr>
    <td><code>status_send_type</code></td>
    <td>How the status is to be published. The default value is <code>OPERATION</code>, meaning that the status is published as a {{< product-c8y-iot >}} operation. You can change this to one of the following values:
      <ul>
         <li><code>EVENT</code> - Publish the status as a {{< product-c8y-iot >}} event.</li>
         <li><code>MEASUREMENT</code> - Publish the status as a {{< product-c8y-iot >}} measurement.</li>
      </ul>
    </td>
  </tr>
  <tr>
    <td><code>status_send_keys</code></td>
    <td>A comma-separated list of field names to be used when publishing the status. If not set or empty, the status for all fields is published. For example, if you specify the following, then the status includes only the values for these fields in one measurement.<br>
    <code>numQueuedInput,numListeners,numMonitors</code></td>
  </tr>
  <tr>
    <td><code>status_event_type</code></td>
    <td>The event type if the status is published as a {{< product-c8y-iot >}} event, or the measurement type if the status is published as a {{< product-c8y-iot >}} measurement. The default type is <code>apama_status</code>.</td>
  </tr>
  <tr>
    <td ><code>status_event_text</code></td>
    <td >The event text if the status is published as a {{< product-c8y-iot >}} event. The default text is <code>Apama Status</code>.</td>
  </tr>
</tbody>
</table>

#### Keys for model timeouts {#keys-for-model-timeouts}

<table>
<colgroup>
    <col style="width: 30%;">
    <col style="width: 70%;">
</colgroup>
<thead>
  <tr>
    <th>Key name</th>
    <th>Description</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td><code>timedelay_secs</code></td>
    <td>The maximum delay in seconds before the input block considers an event to be old. The default value is 1 second. See also <a href="/streaming-analytics/analytics-builder/#input-blocks-and-event-timing">Input blocks and event timing</a>.</td>
  </tr>
  <tr>
    <td><code>logging_throttle_secs</code></td>
    <td>Logging throttling in seconds. Periodic log messages (for example, those reporting changes in the number of events being dropped by the input block) will not appear more frequently than defined by this constant. The default value is 1 second. See also <a href="/streaming-analytics/analytics-builder/#input-blocks-and-event-timing">Input blocks and event timing</a>.</td>
  </tr>
  <tr>
    <td><code>minimum_wait_time_secs</code></td>
    <td>The minimum wait time in seconds. Some blocks can generate output automatically, based on the rate of change of the output. This sets a lower limit on the time between such outputs. See also <a href="/streaming-analytics/analytics-builder/#common-block-inputs-and-parameters">Common block inputs and parameters</a>.</td>
  </tr>
</tbody>
</table>

#### Keys for simulation mode {#keys-for-simulation-mode}

<table>
<colgroup>
    <col style="width: 40%;">
    <col style="width: 60%;">
</colgroup>
<thead>
  <tr>
    <th>Key name</th>
    <th>Description</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td><code>simulation.maxInstances</code></td>
    <td>The maximum number of simulation models to be deployed at a time. The default value is 3 models. See also <a href="/streaming-analytics/analytics-builder/#configuring-the-maximum-number-of-simulation-models">Configuring the maximum number of simulation models</a>.</td>
  </tr>
</tbody>
</table>

#### Other keys {#other-keys}

<table>
<colgroup>
    <col style="width: 40%;">
    <col style="width: 60%;">
</colgroup>
<thead>
  <tr>
    <th>Key name</th>
    <th>Description</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td><code>numWorkerThreads</code></td>
    <td>The number of worker threads. The default value is 1. See also <a href="/streaming-analytics/analytics-builder/#configuring-the-concurrency-level">Configuring the concurrency level</a>.</td>
  </tr>
  <tr>
    <td><code>retention.virtualDevicesMaxDays</code></td>
    <td>The retention period in days for keeping virtual devices. The default value is 30 days. See also <a href="/streaming-analytics/analytics-builder/#virtual-devices">Virtual devices</a>.</td>
  </tr>
  <tr>
    <td><code>c8yAnalyticsBlocks.queryInventoryPageSize</code></td>
    <td>The number of items that are shown in the <b>Select Input Source</b> and <b>Select Output Destination</b> dialog boxes. The default value is 10. See also <a href="/streaming-analytics/analytics-builder/#configuring-the-number-of-shown-input-sources-and-output-destinations">Configuring the number of shown input sources and output destinations</a>.</td>
  </tr>
  <tr>
    <td><code>c8yAnalyticsBlocks.queryInventoryNameSearchAdditionalFilter</code></td>
    <td>The managed objects that are shown when you use the search box and filter checkboxes of the <b>Select Input Source</b> or <b>Select Output Destination</b> dialog box. See also <a href="/streaming-analytics/analytics-builder/#searching-for-devices-groups-andor-assets">Searching for devices, groups and/or assets</a>.</td>
  </tr>
</tbody>
</table>

#### Logged tenant options {#logged-tenant-options}

The values for some of the tenant options are logged. These are the following:

-   `status_device_name`
-   `status_period_secs`
-   `timedelay_secs`
-   `numWorkerThreads`

If you want to find out which values are currently used for these tenant options, you can look them up in the log. See also [Log files of the Apama-ctrl microservice](/streaming-analytics/troubleshooting/#logfiles).

#### Using curl commands for setting various tenant options {#using-curl-commands-for-setting-various-tenant-options}

You can set or change various tenant options by sending `POST` requests to {{< product-c8y-iot >}}. This topic explains how you can do this using the curl command-line tool. See [https://curl.se/](https://curl.se/) for detailed information on curl. See also the information on the [tenant options](https://{{< domain-c8y >}}/api/core/#tag/Options) in the {{< openapi >}}.

The syntax of the curl command depends on the environment in which you are working. The syntax for a Bash UNIX shell, for example, is as follows:

`curl --user username -X POST -H 'Content-Type: application/json' -d '{"category": "analytics.builder", "key": "keyname", "value": "value"}' -k https://hostname/tenant/options`

where:

-   `username` is the name of a user who has ADMIN permission for "Option management" in {{< product-c8y-iot >}}. curl will prompt for a password. Or you can provide a password in the `username` argument by appending it with a colon \(:\) and the password. For example:

    `--user User123:secretpw`

    If your tenant does not have its own unique host name, you must provide the tenant identifier in the `username` argument. For example:

    `--user management/User123`

    or

    `--user t12345/User123`

-   `keyname` is one of the keys listed in the previous topics.
-   `value` is the value that is to be set for the key, which can be a number or a string, depending on the key.
-   `hostname` is the host name of your tenant where your user application is deployed.
-   The `category` is always `analytics.builder`.

**Example (Bash shell):**

`curl --user User123 -X POST -H 'Content-Type: application/json' -d '{"category": "analytics.builder", "key": "numWorkerThreads", "value": "4"}' -k https://mytenant/tenant/options`
